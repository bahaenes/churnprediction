{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Churn Prediction - End-to-End Analysis\n",
    "\n",
    "This notebook contains a complete churn prediction pipeline:\n",
    "\n",
    "1. **Data Generation and Loading**\n",
    "2. **Exploratory Data Analysis (EDA)**\n",
    "3. **Data Preprocessing and Feature Engineering**\n",
    "4. **Model Training and Comparison**\n",
    "5. **Model Evaluation**\n",
    "6. **Model Explainability (SHAP)**\n",
    "7. **Model Persistence**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "from src.data_generator import generate_churn_dataset\n",
    "from src.preprocessing import ChurnDataProcessor\n",
    "from src.model_trainer import ChurnModelTrainer, print_classification_report\n",
    "from src.explainability import (\n",
    "    ChurnExplainer, plot_confusion_matrix, \n",
    "    plot_roc_curve, plot_precision_recall_curve\n",
    ")\n",
    "\n",
    "print('Libraries loaded successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Generation and Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = generate_churn_dataset(n_samples=7000, random_state=42)\n",
    "df.to_csv('../data/telco_churn.csv', index=False)\n",
    "\n",
    "print(f'Dataset created: {df.shape[0]:,} rows, {df.shape[1]} columns')\n",
    "print(f'Churn rate: {(df[\"Churn\"] == \"Yes\").mean():.2%}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Dataset Information')\n",
    "print('=' * 50)\n",
    "print(f'Number of rows: {df.shape[0]:,}')\n",
    "print(f'Number of columns: {df.shape[1]}')\n",
    "print(f'\\nData Types:')\n",
    "print(df.dtypes.value_counts())\n",
    "print(f'\\nMissing Values:')\n",
    "print(df.isnull().sum()[df.isnull().sum() > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "churn_counts = df['Churn'].value_counts()\n",
    "colors = ['#2ecc71', '#e74c3c']\n",
    "axes[0].pie(churn_counts.values, labels=['Retained', 'Churned'], \n",
    "            autopct='%1.1f%%', colors=colors, explode=[0, 0.05],\n",
    "            shadow=True, startangle=90)\n",
    "axes[0].set_title('Churn Distribution', fontsize=14, fontweight='bold')\n",
    "\n",
    "sns.countplot(data=df, x='Churn', hue='Churn', palette={'No': '#2ecc71', 'Yes': '#e74c3c'}, ax=axes[1], legend=False)\n",
    "axes[1].set_title('Churn Counts', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Churn Status')\n",
    "axes[1].set_ylabel('Customer Count')\n",
    "\n",
    "for p in axes[1].patches:\n",
    "    axes[1].annotate(f'{int(p.get_height()):,}', \n",
    "                     (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                     ha='center', va='bottom', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "sns.histplot(data=df, x='tenure', hue='Churn', kde=True, ax=axes[0],\n",
    "             palette={'No': '#2ecc71', 'Yes': '#e74c3c'})\n",
    "axes[0].set_title('Customer Tenure', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Months')\n",
    "\n",
    "sns.histplot(data=df, x='MonthlyCharges', hue='Churn', kde=True, ax=axes[1],\n",
    "             palette={'No': '#2ecc71', 'Yes': '#e74c3c'})\n",
    "axes[1].set_title('Monthly Charges', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('$')\n",
    "\n",
    "sns.histplot(data=df, x='TotalCharges', hue='Churn', kde=True, ax=axes[2],\n",
    "             palette={'No': '#2ecc71', 'Yes': '#e74c3c'})\n",
    "axes[2].set_title('Total Charges', fontsize=14, fontweight='bold')\n",
    "axes[2].set_xlabel('$')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['Contract', 'PaymentMethod', 'InternetService', 'TechSupport', 'OnlineSecurity']\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, col in enumerate(categorical_cols):\n",
    "    churn_rate = df.groupby(col)['Churn'].apply(lambda x: (x == 'Yes').mean() * 100)\n",
    "    churn_rate = churn_rate.sort_values(ascending=False)\n",
    "    \n",
    "    sns.barplot(x=churn_rate.index, y=churn_rate.values, ax=axes[idx], palette='RdYlGn_r')\n",
    "    axes[idx].set_title(f'{col} vs Churn Rate', fontsize=12, fontweight='bold')\n",
    "    axes[idx].set_ylabel('Churn Rate (%)')\n",
    "    axes[idx].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    for p in axes[idx].patches:\n",
    "        axes[idx].annotate(f'{p.get_height():.1f}%', \n",
    "                          (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                          ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "axes[-1].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numeric = df.select_dtypes(include=[np.number])\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "correlation = df_numeric.corr()\n",
    "mask = np.triu(np.ones_like(correlation, dtype=bool))\n",
    "sns.heatmap(correlation, mask=mask, annot=True, cmap='RdYlBu_r', \n",
    "            center=0, fmt='.2f', linewidths=0.5)\n",
    "plt.title('Correlation Matrix', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = ChurnDataProcessor()\n",
    "df = processor.load_data('../data/telco_churn.csv')\n",
    "X_train, X_test, y_train, y_test = processor.prepare_data(df, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f'Data preparation complete')\n",
    "print(f'Number of features: {X_train.shape[1]}')\n",
    "print(f'Feature list: {list(X_train.columns)[:10]}...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training Set - First 5 Rows:')\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Training and Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = ChurnModelTrainer()\n",
    "\n",
    "results = trainer.train_all_models(\n",
    "    X_train, y_train,\n",
    "    X_test, y_test,\n",
    "    use_sampling='smote'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df = trainer.compare_models()\n",
    "print('Model Comparison:')\n",
    "print('=' * 80)\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC AUC']\n",
    "x = np.arange(len(comparison_df))\n",
    "width = 0.15\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    ax.bar(x + i * width, comparison_df[metric], width, label=metric)\n",
    "\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('Model Performance Comparison', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x + width * 2)\n",
    "ax.set_xticklabels(comparison_df['Model'], rotation=45, ha='right')\n",
    "ax.legend(loc='lower right')\n",
    "ax.set_ylim(0.5, 1.0)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_name, best_model = trainer.select_best_model(metric='roc_auc')\n",
    "print_classification_report(y_test, results[best_model_name]['y_pred'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_results = results[best_model_name]\n",
    "plot_confusion_matrix(best_results['confusion_matrix'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve(y_test, best_results['y_proba'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_precision_recall_curve(y_test, best_results['y_proba'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "for name, res in results.items():\n",
    "    fpr, tpr, _ = roc_curve(y_test, res['y_proba'])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, lw=2, label=f'{name} (AUC = {roc_auc:.3f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=12)\n",
    "plt.ylabel('True Positive Rate', fontsize=12)\n",
    "plt.title('ROC Curve Comparison', fontsize=14, fontweight='bold')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Explainability (SHAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = ChurnExplainer(best_model, X_train.columns.tolist())\n",
    "explainer.create_explainer(X_train, explainer_type='tree')\n",
    "shap_values = explainer.calculate_shap_values(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer.plot_summary(X_test, max_display=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer.plot_bar(X_test, max_display=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_features = explainer.get_top_features(top_n=10)\n",
    "print('Top 10 Most Important Features:')\n",
    "print('=' * 40)\n",
    "top_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_risk_idx = np.argmax(best_results['y_proba'])\n",
    "print(f'High Risk Customer (Index: {high_risk_idx})')\n",
    "print(f'Churn Probability: {best_results[\"y_proba\"][high_risk_idx]:.2%}')\n",
    "print('\\nCustomer Features:')\n",
    "print(X_test.iloc[high_risk_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer.explain_instance(X_test, high_risk_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_risk_explanations = explainer.explain_high_risk_customers(\n",
    "    X_test, best_results['y_proba'], top_n=3\n",
    ")\n",
    "\n",
    "print('Top 3 High Risk Customers Analysis:')\n",
    "print('=' * 60)\n",
    "\n",
    "for idx, explanation in high_risk_explanations.items():\n",
    "    print(f'\\nCustomer Index: {idx}')\n",
    "    print(f'   Churn Probability: {explanation[\"churn_probability\"]:.2%}')\n",
    "    print('   Risk Factors:')\n",
    "    for factor in explanation['top_factors'][:3]:\n",
    "        direction = 'increases' if factor['direction'] == 'increases' else 'decreases'\n",
    "        print(f'   - {factor[\"feature\"]}: {factor[\"shap_value\"]:.3f} ({direction} risk)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Model and Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "models_dir = Path('../models')\n",
    "models_dir.mkdir(exist_ok=True)\n",
    "\n",
    "trainer.save_model(str(models_dir / 'best_model.joblib'))\n",
    "processor.save_processor(str(models_dir / 'processor.joblib'))\n",
    "\n",
    "model_results = {\n",
    "    'model_name': best_model_name,\n",
    "    'accuracy': best_results['accuracy'],\n",
    "    'precision': best_results['precision'],\n",
    "    'recall': best_results['recall'],\n",
    "    'f1': best_results['f1'],\n",
    "    'roc_auc': best_results['roc_auc'],\n",
    "    'feature_columns': X_train.columns.tolist()\n",
    "}\n",
    "\n",
    "joblib.dump(model_results, str(models_dir / 'model_results.joblib'))\n",
    "\n",
    "print('All artifacts saved:')\n",
    "print('   - best_model.joblib')\n",
    "print('   - processor.joblib')\n",
    "print('   - model_results.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Summary\n",
    "\n",
    "### Completed Tasks:\n",
    "1. Generated synthetic dataset with 7,000 customer records\n",
    "2. Performed comprehensive exploratory data analysis\n",
    "3. Engineered 10+ new features\n",
    "4. Trained and compared 5 different models\n",
    "5. Selected best performing model based on ROC AUC\n",
    "6. Implemented SHAP for model explainability\n",
    "7. Persisted model and preprocessing artifacts\n",
    "\n",
    "### Next Steps:\n",
    "- Run the Streamlit app: `streamlit run app/streamlit_app.py`\n",
    "- Use the dashboard for predictions\n",
    "- Update model with real data when available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=' * 60)\n",
    "print('CHURN PREDICTION PROJECT COMPLETE')\n",
    "print('=' * 60)\n",
    "print(f'\\nBest Model: {best_model_name}')\n",
    "print(f'ROC AUC Score: {best_results[\"roc_auc\"]:.4f}')\n",
    "print(f'F1 Score: {best_results[\"f1\"]:.4f}')\n",
    "print('\\nTo launch Streamlit dashboard:')\n",
    "print('   cd churn_prediction && streamlit run app/streamlit_app.py')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
